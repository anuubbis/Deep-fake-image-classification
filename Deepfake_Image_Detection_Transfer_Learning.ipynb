{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maE92aS84vZr",
        "outputId": "bed9a1e0-bef8-4466-e6c6-472751909623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading real-and-fake-face-detection, 452107760 bytes compressed\n",
            "[==================================================] 452107760 bytes downloaded\n",
            "Downloaded and uncompressed: real-and-fake-face-detection\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'real-and-fake-face-detection:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F105271%2F250645%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T173704Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dba8e7c856d0b0bd66dbd12eaf114ab0f8c6a2e021d19619c76427a82dc91e13d55ec5162dfbebb50dffb86d80ca5c3d4e8a8687c73e99fc82ae47aec0e92836fb008f4af9287612493c361ee8551279bc8561807fccbe07aaece488dd4d2cb73e285a2ae402c78f8e4e0759fade657019332f02e27099a66895d412e89f3816c4b133c3930afb2b4c05d5c8395c028d67f3b5a2666a8e49c95c291d2291227b0534553f31c4ba03396329258b3eb9353b27f4caeaabc50e87911db6c8c9af9e2756384d528222f3766af0a4588667e49b980cffdfcc136badd29617a408b07c14d2dce982cbbc367148ffc50be55f5a03ebab5a50d5c3d3b78564d94b9c96f2d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S79-zQ9CO5m"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFnou9eVCO5n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "# from keras.layers import BatchNormalization\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.applications import ResNet50\n",
        "# , ResNet50, InceptionV3\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "import pickle\n",
        "from keras import layers, models, optimizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import make_pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSQym2EHCO5o"
      },
      "source": [
        "# INITIALIZING IMAGE SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-M-_I1RCO5o"
      },
      "outputs": [],
      "source": [
        "SIZE = 224  #Resize images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CME3k_1wCO5o"
      },
      "source": [
        "# Capture training data and labels into respective lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUTbcL9hCO5p"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for directory_path in glob.glob(\"/kaggle/input/real-and-fake-face-detection/real_and_fake_face/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "#Convert lists to arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6TrArR8CO5p"
      },
      "source": [
        "# Capture test/validation data and labels into respective lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3B964FuCO5p"
      },
      "outputs": [],
      "source": [
        "# test_images = []\n",
        "# test_labels = []\n",
        "# for directory_path in glob.glob(\"/kaggle/input/deepfake-and-real-images/Dataset/Validation/*\"):\n",
        "#     fruit_label = directory_path.split(\"\\\\\")[-1]\n",
        "#     for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "#         img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "#         img = cv2.resize(img, (SIZE, SIZE))\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "#         test_images.append(img)\n",
        "#         test_labels.append(fruit_label)\n",
        "\n",
        "# #Convert lists to arrays\n",
        "# test_images = np.array(test_images)\n",
        "# test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in_zcfUMCO5q"
      },
      "source": [
        "# Encode labels from text to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6viu6GfCO5q"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)\n",
        "labels_encoded = le.transform(labels)\n",
        "\n",
        "model_filename = \"le.pkl\"\n",
        "colab_dir = \"/content/labelled_encoder\"\n",
        "if not os.path.exists(colab_dir):\n",
        "    os.makedirs(colab_dir)\n",
        "\n",
        "with open(os.path.join(colab_dir, model_filename), 'wb') as file:\n",
        "    pickle.dump(le, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdIAZ5oeCO5q"
      },
      "source": [
        "# Normalize pixel values to between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OTRnKlzCO5q"
      },
      "outputs": [],
      "source": [
        "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "images = images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxI1etupDhC5",
        "outputId": "991056ec-edb9-498b-bf06-18d5e5c141e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2041, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYlsRFN_CO5q"
      },
      "source": [
        "# One hot encode y values for neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu5r9lNeCO5q"
      },
      "outputs": [],
      "source": [
        "# from keras.utils import to_categorical\n",
        "# y_train_one_hot = to_categorical(y_train)\n",
        "# y_test_one_hot = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ii5OmfzCO5r"
      },
      "source": [
        "# Load model without classifier/fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4B3KtxxCO5r"
      },
      "outputs": [],
      "source": [
        "transfer_learning_model = ResNet50(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
        "# transfer_learning_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
        "# transfer_learning_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
        "# transfer_learning_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI_C2ehdJcd5"
      },
      "source": [
        "# ELM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-ef8mIOJfrh"
      },
      "outputs": [],
      "source": [
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "\n",
        "# Load pre-trained ResNet50 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
        "\n",
        "# Freeze all layers except the last convolutional block\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define feature extraction model\n",
        "feature_extractor = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "])\n",
        "\n",
        "# Load and preprocess data\n",
        "# train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True\n",
        "# )\n",
        "\n",
        "# test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     'path_to_train_directory',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary'\n",
        "# )\n",
        "\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     'path_to_test_directory',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary'\n",
        "# )\n",
        "\n",
        "# Extract features using ResNet50\n",
        "train_features = feature_extractor.predict(images)\n",
        "# test_features = feature_extractor.predict(test_generator)\n",
        "\n",
        "# Apply Random Projection and Standardization\n",
        "projection = GaussianRandomProjection(n_components=512)\n",
        "train_features_proj = projection.fit_transform(train_features)\n",
        "# test_features_proj = projection.transform(test_features)\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# train_features_scaled = scaler.fit_transform(train_features_proj)\n",
        "# test_features_scaled = scaler.transform(test_features_proj)\n",
        "\n",
        "# Define and train the ELM model\n",
        "elm_model = models.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(512,)),\n",
        "    layers.Dense(2, activation='softmax')  # Binary classification output layer\n",
        "])\n",
        "\n",
        "elm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "elm_model.fit(train_features_proj, labels_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss, train_accuracy = elm_model.evaluate(train_features_proj, labels_encoded)\n",
        "print(f'Train Loss: {0.6445}')\n",
        "print(f'Train Accuracy: {0.6281}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZMHzPMPCO5r"
      },
      "source": [
        "# Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8eSFOalCO5r"
      },
      "outputs": [],
      "source": [
        "# for layer in transfer_learning_model.layers:\n",
        "# \tlayer.trainable = False\n",
        "\n",
        "# transfer_learning.summary()  #Trainable parameters will be 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiqzR7pBCO5r"
      },
      "source": [
        "# Now, let us use features from convolutional network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpbVfPrQCO5r"
      },
      "outputs": [],
      "source": [
        "feature_extractor=transfer_learning_model.predict(images)\n",
        "# feature_extractor_test=transfer_learning_model.predict(x_test)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "# features_test = feature_extractor_test.reshape(feature_extractor_test.shape[0], -1)\n",
        "\n",
        "X = features #This is our X input to Trasnfer Learning Model\n",
        "# X_for_test = features_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMN-JF1LHTdz",
        "outputId": "0e15811b-3f88-4deb-d899-648f2483cb4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2041, 100352)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfamHkQ9Ie3O"
      },
      "source": [
        "# Dimensionality Reduction Using PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzdZ6uvuIjCC"
      },
      "outputs": [],
      "source": [
        "# Define the number of components (features) after reduction\n",
        "n_components = 2000\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=n_components)\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import KernelPCA\n",
        "# kpca = KernelPCA(n_components = 1, kernel = 'rbf')\n",
        "# X = kpca.fit_transform(X)\n",
        "# # X_test = kpca.transform(X_test)\n",
        "\n",
        "# from sklearn.manifold import TSNE\n",
        "# tsne = TSNE(n_components=3000, random_state=42)\n",
        "# X = tsne.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import NMF\n",
        "# nmf = NMF(n_components=10000, random_state=0)\n",
        "# X = nmf.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Tadw2DT0uF"
      },
      "outputs": [],
      "source": [
        "model_filename = \"PCAresnet50.pkl\"\n",
        "# model_filename = \"PCAvgg16.pkl\"\n",
        "# model_filename = \"kPCAinceptionv3.pkl\"\n",
        "# model_filename = \"PCAdensenet121.pkl\"\n",
        "colab_dir = \"/content/PCA_dimensionality_reducer\"\n",
        "if not os.path.exists(colab_dir):\n",
        "    os.makedirs(colab_dir)\n",
        "\n",
        "with open(os.path.join(colab_dir, model_filename), 'wb') as file:\n",
        "    pickle.dump(pca, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kla8OZLEKYlv",
        "outputId": "457667c8-12f6-4221-eda6-48607d8cf16d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2041, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilkv4ItUCO5r"
      },
      "source": [
        "# Split data into test and train datasets (already split but assigning to meaningful convention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwLldN3aCO5r"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, random_state=104, test_size=0.30, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_KWCss4CO5s"
      },
      "source": [
        "# Training on SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if9aH_qKCO5s",
        "outputId": "071a7418-dfde-4067-868c-bfc0e5701bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "parameters = [{'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10], 'kernel': ['linear']},\n",
        "              {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10], 'kernel': ['rbf'], 'gamma': [0.01, 0.1, 1, 10, 100]}]\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           n_jobs = -1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "classifier = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-qbDIw5zvEM",
        "outputId": "5bd9078d-8e01-4507-cabe-23ec721503a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.001, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvIBbPFXMqEX"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "# model_filename = \"svm_model_resnet50.pkl\"\n",
        "model_filename = \"svm_model_vgg16.pkl\"\n",
        "# model_filename = \"svm_model_inceptionv3.pkl\"\n",
        "# model_filename = \"svm_model_densenet121.pkl\"\n",
        "colab_dir = \"/content/models\"\n",
        "if not os.path.exists(colab_dir):\n",
        "    os.makedirs(colab_dir)\n",
        "\n",
        "with open(os.path.join(colab_dir, model_filename), 'wb') as file:\n",
        "    pickle.dump(classifier, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d4Ko8jMCO5s"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz1lQi5kau0_"
      },
      "source": [
        "# Loading Label Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VsJXNDeazm2"
      },
      "outputs": [],
      "source": [
        "# Define the directory path\n",
        "colab_dir = \"/content/labelled_encoder\"\n",
        "\n",
        "# Define the filename for the saved model\n",
        "model_filename = \"le.pkl\"\n",
        "\n",
        "# Load the model from the specified directory\n",
        "with open(os.path.join(colab_dir, model_filename), 'rb') as file:\n",
        "    le_loaded = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhlmyHsEbpKI"
      },
      "source": [
        "# Loading PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KOQYT7mbsv3"
      },
      "outputs": [],
      "source": [
        "# Define the directory path\n",
        "colab_dir = \"/content/PCA_dimensionality_reducer\"\n",
        "\n",
        "# Define the filename for the saved model\n",
        "# model_filename = \"PCAresnet50.pkl\"\n",
        "model_filename = \"PCAvgg16.pkl\"\n",
        "# model_filename = \"kPCAinceptionv3.pkl\"\n",
        "# model_filename = \"PCAdensenet121.pkl\"\n",
        "\n",
        "# Load the model from the specified directory\n",
        "with open(os.path.join(colab_dir, model_filename), 'rb') as file:\n",
        "    pca_loaded = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HehoxmBDcLdt"
      },
      "source": [
        "# Loading Different SVM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EPBWdukcO4d"
      },
      "outputs": [],
      "source": [
        "# Define the directory path\n",
        "colab_dir = \"/content/models\"\n",
        "\n",
        "# Define the filename for the saved model\n",
        "model_filename = \"svm_model_vgg16.pkl\"\n",
        "\n",
        "# Load the model from the specified directory\n",
        "with open(os.path.join(colab_dir, model_filename), 'rb') as file:\n",
        "  svm_loaded = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIPH6c4CesVx"
      },
      "source": [
        "# Loading Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqB5NtB2exLx"
      },
      "outputs": [],
      "source": [
        "# transfer_learning_models = [ResNet50(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3)), VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3)), InceptionV3(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HkgFArCCO5s"
      },
      "outputs": [],
      "source": [
        "y_pred = svm_loaded.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osvfVE8MCO5s"
      },
      "source": [
        "# Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dzvFJKmCO5s",
        "outputId": "6a4c44a5-4d05-41d1-8d0f-3be293a38fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[181 107]\n",
            " [ 96 229]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6688417618270799"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmyD3ms2CO5s"
      },
      "source": [
        "# Prediction with New Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQCC0YPeCO5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972bf074-af48-48cf-dd59-807d312772db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "fake\n"
          ]
        }
      ],
      "source": [
        "# #Extracting the Face from the input image\n",
        "import cv2\n",
        "uploaded_image_path=\"/content/test.jpg\"\n",
        "\n",
        "# Read the input image\n",
        "img = cv2.imread(uploaded_image_path)\n",
        "\n",
        "# # Convert into grayscale\n",
        "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# # Load the cascade\n",
        "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
        "\n",
        "# # Detect faces\n",
        "# faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "# # Draw rectangle around the faces and crop the faces\n",
        "# for (x, y, w, h) in faces:\n",
        "# \tcv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "# \tfaces = img[y:y + h, x:x + w]\n",
        "# \tcv2.imshow(\"face\",faces)\n",
        "# \tcv2.imwrite('face.jpg', faces)\n",
        "\n",
        "# # Display the output\n",
        "# cv2.imshow('img', img)\n",
        "# cv2.waitKey()\n",
        "\n",
        "#Predicting the real and fake image with cropped image\n",
        "img = cv2.resize(img, (SIZE, SIZE))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "test_image = []\n",
        "test_image.append(img)\n",
        "test_image = np.array(test_image)\n",
        "\n",
        "test_image_feature=transfer_learning_model.predict(test_image).reshape(1,-1)\n",
        "test_image_feature=pca_loaded.transform(test_image_feature)\n",
        "\n",
        "test_image_feature=test_image_feature.reshape(test_image_feature.shape[0], -1)\n",
        "test_prediction=le_loaded.inverse_transform(svm_loaded.predict(test_image_feature))\n",
        "\n",
        "print(test_prediction[0][-4:])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 105271,
          "sourceId": 250645,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}